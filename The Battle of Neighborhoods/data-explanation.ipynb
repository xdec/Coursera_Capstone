{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# The Battle of Neighbourhoods\n",
    "\n",
    "### Introduction\n",
    "New York City is known as one of the most expensive cities in the world. Property prices in this city are among the highest in the world. This makes New York an attractive - yet equally competitive - market for realtors.\n",
    "\n",
    "We're going to dive deeper into the property market to find out which districts and neighbourhoods are likely to provide realtors with the highest returns. We'll take a look at sales data from 2020 and use both median prices as well as the number of transactions to arrive at a conclusion.\n",
    "\n",
    "As a secondary objective, we'll test the hypothesis that people are willing to pay more when there are more amenities close by - as there would be a perceived increase in convenience. We're expecting the average rating for the nearby locations to be in an average range between 3.5 and 4.0 as people in these areas are likely to have high expectations.\n",
    "\n",
    "### Data\n",
    "#### We'll be using data from the following sources:\n",
    "- [Foursquare](https://foursquare.com/) - Foursquare will be used to grab location data for the different neighbourhoods. It will include the latitudes and longitudes, as well as data for the locations nearest to a set of coordinates.\n",
    "- [OpenCage Geocoder](https://opencagedata.com/) - Geocoder will be used to generate the coordinates for each of the different locations, which will then be used to visualize the locations on a map using folium.\n",
    "- [Timeout](https://www.timeout.com/newyork/news/these-are-the-new-most-expensive-neighborhoods-in-nyc-010621) - Timeout will be used to scrape the sales data required for both the median prices and the number of transactions per location.\n",
    "\n",
    "#### We'll use the following process:\n",
    "1. Use pandas to scrape the table in the Timeout article and extract the data we need\n",
    "2. Add the data to a pandas dataframe\n",
    "3. Process the data and ensure it's in a usable state\n",
    "4. Use Geocoder to generate coordinates for each location\n",
    "5. Merge the coordinates data with dataframe containing the Timeout data\n",
    "6. Plot the coordinates onto a map to get our first visual representation of the data\n",
    "7. Use the Foursquare API to get the necessary data related to our secondary objective\n",
    "8. Merge this data with the existing dataframe\n",
    "9. Plot the coordinates onto a map to get another visual representation of the data\n",
    "10. Run the dataframe through a KMeans clustering algorithm\n",
    "11. Merge the KMeans cluster data with the existing dataframe\n",
    "12. Plot the coordinates onto a map and get a final visual representation of the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}